---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 1 with R (STAT 301-1)
author: "Ada Liu"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
---

::: {.callout-tip icon=false}

## Github Repo Link

[https://github.com/stat301-1-2023-fall/final-project-1-adacliu.git](https://github.com/stat301-1-2023-fall/final-project-1-adacliu.git)

:::

::: {.callout-tip icon="false"}
## Data Collecting and Cleaning

For my EDA, I decided on using only the two datasets I mentioned in my first progress meme, the Global Terrorism Database and the Polity IV dataset as I found them comprehensive and included a variety of variables. I did my data cleaning in my 0b_data_cleaning .R file, which included removing variables from both datasets that had huge missingness issue, in my case, over 50% missing. Since the earliest entry in the Polity dataset was 1776 and the latest entry in the GTD was 2017, I dropped any entries prior to 1776 from the GTD dataset and any entries after 2017 in the Polity dataset. Further, I changed some of the column names (ie, "country_txt" to "country_name") in the datasets to facilitate merging. I used the compound key "country_name" and "year" from the Polity dataset to join the two datasets and then cleaned up this new, combined dataset by removing any variables that I was not interested in working with and changed unknown values to "NA". I decided to keep 41 variables in my final dataset, giving me a wide variety of variables to work with and explore.  Finally, I created text file codebook to document what each variable is. 
 
:::

::: {.callout-tip icon="false"}
## Data overview and quality

After I combined and cleaned my two raw datasets, the dataset I will be using for my EDA has 43 variables and very little missingness issues. There are 11 categorical variables and 30 numerical variables with 175,790 observations. 
:::

